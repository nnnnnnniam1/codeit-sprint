import os
import pandas as pd
import numpy as np
from joblib import dump
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.linear_model import Ridge
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import root_mean_squared_error
import matplotlib.pyplot as plt
from datetime import datetime, timedelta, timezone
# 1. ë°ì´í„° ê²½ë¡œ

DATA_DIR = os.environ.get("DATA_DIR", './data')
train_path = os.path.join(DATA_DIR, 'mission15_train.csv')

df = pd.read_csv(train_path)

# 2. Feature / Target ë¶„ë¦¬
X = df.drop(columns=['Performance Index'])
y = df['Performance Index']

# 3. ì „ì²˜ë¦¬
num_features = ['Hours Studied', 'Previous Scores', 'Sleep Hours', 'Sample Question Papers Practiced']
category_features = ['Extracurricular Activities']

preprocessor = ColumnTransformer(
  transformers=[
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown="ignore"), category_features)
  ]
)

# 4. ë°ì´í„° ë¶„í• 
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)
print(f"ğŸ“Š í•™ìŠµ ë°ì´í„°: {X_train.shape}, ê²€ì¦ ë°ì´í„°: {X_val.shape}")

# 5. ëª¨ë¸
models = {
  'Ridge': {
    'estimator': Pipeline([
      ('preprocess', preprocessor),
      ('model', Ridge())
    ]),
    'param_grid': {
      'model__alpha': [0.01, 0.1, 1.0, 10.0, 100.0],
      'model__solver': ['auto', 'saga']
    }
  },
  'RandomForest': {
    'estimator': Pipeline([
      ('preprocess', preprocessor),
      ('model', RandomForestRegressor(random_state=42))
    ]),
    'param_grid': {
      'model__n_estimators': [100, 200, 300],
      'model__max_depth': [None, 5, 10, 20],
      'model__min_samples_split': [2, 5, 10],
      'model__max_features': ['sqrt', 'log2', None]
    }
  }
}

# 6. ëª¨ë¸ í•™ìŠµ ë° RMSE í‰ê°€

best_rmse = float('inf')
best_model_name = None
best_model = None


# í•œêµ­ í‘œì¤€ì‹œ (UTC+9)
KST = timezone(timedelta(hours=9))
timestamp = datetime.now(KST).strftime("%Y%m%d_%H%M%S")


# ê²°ê³¼ ì €ì¥ í´ë” ìƒì„±(ë‚ ì§œ_ì‹œê°„)
SHARED_DIR = os.environ.get("SHARED_DIR", "/app/shared")
save_dir = os.path.join(SHARED_DIR, timestamp)
os.makedirs(save_dir, exist_ok=True)
print(f"ğŸ“ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {save_dir}")


# 6. ëª¨ë¸ í•™ìŠµ ë° RMSE í‰ê°€
for name, cfg in models.items():
  print(f'\nğŸš€ {name} ëª¨ë¸ íŠœë‹ ì¤‘...')
  grid = GridSearchCV(
    estimator=cfg['estimator'],
    param_grid=cfg['param_grid'],
    scoring='neg_root_mean_squared_error',
    cv=5,
    n_jobs=-1
  )
  
  grid.fit(X_train, y_train)
  rmse = -grid.best_score_
  
  
  # GridSearch ê²°ê³¼ ì €ì¥
  results_df = pd.DataFrame(grid.cv_results_)
  results_df.to_csv(f"{save_dir}/{name}_gridsearch_results.csv", index=False)

  
  print(f"âœ… {name} Best RMSE (CV): {rmse:.4f}")
  print(f"âœ… {name} Best Params: {grid.best_params_}")
  
  if rmse < best_rmse:
    best_rmse = rmse
    best_model_name = name
    best_model = grid.best_estimator_
  

# 7. ê²€ì¦ ë°ì´í„° ìµœì¢…í‰ê°€
y_pred = best_model.predict(X_val)
val_rmse = root_mean_squared_error(y_val, y_pred)
print(f"\nğŸ¯ ìµœì¢… ì„ íƒ ëª¨ë¸: {best_model_name}")
print(f"ğŸ“‰ Validation RMSE: {val_rmse:.4f}")

# 8. í”¼ì²˜ ì¤‘ìš”ë„ / ê°€ì¤‘ì¹˜ ì¶œë ¥
model = best_model.named_steps['model']
pre = best_model.named_steps['preprocess']
feature_names = pre.get_feature_names_out()

if best_model_name == 'Ridge':
  coef_df = pd.DataFrame({
    'Feature': feature_names,
    'Weight': model.coef_
  }).sort_values(by='Weight', ascending=False)
  
  print("\nğŸ“Š Ridge Feature Weights:")
  print(coef_df)
  
  plt.figure(figsize=(8, 4))
  plt.barh(coef_df["Feature"], coef_df["Weight"], color="steelblue")
  plt.title("Ridge Feature Weights (After Tuning)")
  plt.gca().invert_yaxis()
  plt.tight_layout()
  plt.show()

elif best_model_name == 'RandomForest':
  importance_df = pd.DataFrame({
    'Feature': feature_names,
    'Importance': model.feature_importances_
  }).sort_values(by='Importance', ascending=False)
  
  print("\nğŸŒ² RandomForest Feature Importances:")
  print(importance_df)
  
  plt.figure(figsize=(8, 4))
  plt.barh(importance_df["Feature"], importance_df["Importance"], color="forestgreen")
  plt.title("RandomForest Feature Importances (After Tuning)")
  plt.gca().invert_yaxis()
  plt.tight_layout()
  plt.show()
  


# 9. ìµœì¢… ëª¨ë¸ ì €ì¥
dump(best_model, f'{save_dir}/model.pkl')
print("ğŸ’¾ model.pkl ì €ì¥ ì™„ë£Œ")
print(f"ğŸ Best Model: {best_model_name} (RMSE={val_rmse:.4f})")

